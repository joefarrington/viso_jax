{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joefarrington/viso_jax/blob/main/notebooks/reproduce_viso_jax_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FL1fqn8v7FQZ"
      },
      "source": [
        "# Reproduce experiments from \"Going faster to see further: GPU-accelerated value iteration and simulation for perishable inventory control\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v71nuaTIKL_K"
      },
      "source": [
        "# Introduction\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sq9ZoCGayK5"
      },
      "source": [
        "This notebook accompanies the paper \"*Going faster to see further: GPU-accelerated value iteration and simulation for perishable inventory control*\". It provides a way to reproduce the main experiments without a local GPU, and without requiring any local setup. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6uiS2Fvx6I"
      },
      "source": [
        "If you are new to Google Colab, you may wish to first work through this [introductory notebook](https://colab.research.google.com/) and/or read the [FAQ](https://research.google.com/colaboratory/faq.html). "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "npiph-uHkVxi"
      },
      "source": [
        "This notebook was last tested on 2023-05-27. Subsequent changes to the GPU drivers and default Python environment on Google Colab may cause compatability issues, please raise an issue on the GitHub respository if you encounter one. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "knOIZ8H3rwtA"
      },
      "source": [
        "## Using a GPU runtime on Colab\n",
        "\n",
        "Colab provides access to free cloud-based GPUs. This notebook is set to use a GPU runtime by default. Running the cell below will print the details of the GPU. If it fails, go to the menu on the top left of the screen and select **Runtime** -> **Change runtime type**. Select **GPU** from the dropdown list for hardware accelerator.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l5J3l4dsBXx"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TMLkE-r88Xv_"
      },
      "source": [
        "## Value iteration wall time and checkpoints"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LX30KwVd8Xti"
      },
      "source": [
        "Our value iteration method can save checkpoints at the end of each iteration, which can be used to restart value iteration if Colab times out. \n",
        "\n",
        "While testing this notebook, we observed that saving checkpoints is much slower on Colab than on our local development machine and this can lead to significantly increased wall times for some settings.\n",
        "\n",
        "We therefore provide an option to set the checkpoint frequency for Scenerio A and Scenario B - a checkpoint frequency of 0 corresponds to not saving checkpoints at all. These are set by default to 100 for Scenario A and 1 for Scenario B, the frequencies we used for the results reported in paper.\n",
        "\n",
        "For Scenario C, the checkpoints are required for the convergence test and therefore we do not provide this option. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LM3Ua3Fwry7v"
      },
      "source": [
        "## Mounting Google Drive for permanent storage\n",
        "\n",
        "Colab provides you with a temporary working directory.  This working space is not permanent, and any outputs stored in this space may be lost when the runtime is restarted. \n",
        "\n",
        "If you want to store outputs, you can [mount your Google Drive onto Colab](https://colab.research.google.com/notebooks/io.ipynb). If you mount your Google Drive to this notebook, the viso_jax GitHub repo will be cloned onto your Google Drive and any outputs/checkpoints will be stored on your Google Drive. This will be particularly helpful if you want to run any of the longer experiments and be able to restart them from a checkpoint if Colab times out. \n",
        "\n",
        "To mount your Google Drive, check the box for the variable `mount_google_drive` at the start of the [Setup](#setup) section, run that cell, and follow the instructions to authorize the process before running the next cell."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WVQmp00Kry5X"
      },
      "source": [
        "## Running experiments\n",
        "\n",
        "First, run all of the cells in the [Setup](#setup) section to clone the viso_jax GitHub repository, and install viso_jax and its dependencies. Once setup has been completed, the cells in the [Run experiments](#run-experiments) section can be run in any order.\n",
        "\n",
        "Each form corresponds to a scenario in the paper. Use the dropdown boxes to select the maximum useful life $m$, the ID number of the experiment, and whether to use value iteration or simulation optimization to reproduce the results for the specified experiment using the specified method."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o_RR7_PAry0m"
      },
      "source": [
        "## Advanced\n",
        "\n",
        "The [Advanced](#advanced) section demonstrates how to:\n",
        "* restart value iteration from a checkpoint\n",
        "* reduce the GPU memory requirements\n",
        "* run value iteration at single-precision\n",
        "* run experiments using different random seeds, and;\n",
        "* change a scenario setting to run a modified version of an experiment. \n",
        "\n",
        "The cells within each subsection should be run in order (but the subsections are independent)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TA3oa-zG2dhA"
      },
      "source": [
        "## Running this notebook locally\n",
        "\n",
        "This notebook can be run locally, as a [Jupyter Notebook](https://jupyter.org/). We recommend that you follow the installation instructions for viso_jax on the [README](https://github.com/joefarrington/viso_jax) page of the GitHub repository, and then run the notebook using the local virtual environment in which you have installed viso_jax. \n",
        "\n",
        "Enter the path to the local copy of the viso_jax git repository in the final cell of the [Setup](#setup) section so that subsequent commands that move between directories start in the correct place. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eLGPorgMKE_8"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dBOyIUEy-wGB"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "mount_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "if mount_google_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1rloL5PY-w1K"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# If we're in a Colab notebook, pull any changes to viso_jax repo (or create if it doesn't exist)\n",
        "# and install viso_jax and dependencies\n",
        "# This process is more complicated on Colab due to changes in default packages and drivers\n",
        "if 'google.colab' in sys.modules:\n",
        "  try:\n",
        "    # If Google Drive successfully mounted, clone into drive\n",
        "    os.chdir(\"/content/gdrive/MyDrive\");\n",
        "  except:\n",
        "    # Otherwise clone into the temporary\n",
        "    os.chdir(\"/content/\")\n",
        "  !git -C viso_jax pull || git clone https://joefarrington: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@github.com/joefarrington/viso_jax.git viso_jax;\n",
        "  viso_jax_dir = Path(\"viso_jax\").absolute()\n",
        "  os.chdir(\"viso_jax\");\n",
        "\n",
        "  # Install jedi to avoid Colab error\n",
        "  !pip install jedi>=0.10 > install_jedi.log\n",
        "  # Install our package\n",
        "  !pip install . > install_viso_jax.log\n",
        "  # New default on Colab, manually specify versions of chex and orbax-checkpoint\n",
        "  !pip install chex==0.1.6\n",
        "  !pip install orbax-checkpoint==0.1.1\n",
        "  # Manually specify version of jax and jaxlib; Colab seems to prefer this to reading it from pyproject.toml\n",
        "  !pip install jax==0.3.25 > install_jax.log\n",
        "  !pip install \"jax[cuda11_cudnn82]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html > install_jaxlib.log\n",
        "\n",
        "\n",
        "# If we're not in a Colab notebook, don't take any of those actions and ask the user to manually add the path to the viso_jax github repo in the cell below\n",
        "else:\n",
        "  print(\"Current environment appears not to be a Colab notebook. Ensure that viso_jax has been installed in current environment. Add the path the local copy of the viso_jax git repo in the field below.\")\n",
        "\n",
        "# See https://stackoverflow.com/questions/74117246/python-logging-module-not-working-in-google-colab\n",
        "import logging\n",
        "# Remove all handlers associated with the root logger object, and update config\n",
        "# to print value iteration and simopt logs as output\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "logging.basicConfig(level=logging.INFO,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eu-ygPAg-0wL"
      },
      "outputs": [],
      "source": [
        "#@title Add path to repo if running locally\n",
        "path_to_local_viso_jax_git_repo = \"\" #@param {type:\"string\"}\n",
        "if 'google.colab' not in sys.modules:\n",
        "  viso_jax_dir = Path(f\"path_to_local_viso_jax_git_repo\").absolute()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PuZTPjycKIhr"
      },
      "source": [
        "# Run experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wirj2QuN-2S8"
      },
      "outputs": [],
      "source": [
        "#@title Run an experiment for Scenario A\n",
        "m = \"2\" #@param [\"2\", \"3\", \"4\", \"5\"]\n",
        "experiment = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
        "method = \"Value iteration\" #@param [\"Value iteration\", \"Simulation optimization\"]\n",
        "checkpoint_frequency = 100 #@param {type:\"slider\", min:0, max:500, step:1}\n",
        "\n",
        "if method == \"Value iteration\":\n",
        "  os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "  !python run_value_iteration.py +experiment=de_moor_perishable/m{m}/exp{experiment} vi_runner.checkpoint_frequency={checkpoint_frequency}\n",
        "elif method == \"Simulation optimization\":\n",
        "  os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "  !python run_optuna_simopt.py +experiment=de_moor_perishable/m{m}/exp{experiment}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cKldzCKAF-sN"
      },
      "outputs": [],
      "source": [
        "#@title Run an experiment for Scenario B\n",
        "m = \"2\" #@param [\"2\", \"3\"]\n",
        "experiment = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"P1\", \"P2\", \"P3\", \"P4\"]\n",
        "method = \"Value iteration\" #@param [\"Value iteration\", \"Simulation optimization\"]\n",
        "checkpoint_frequency = 1 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "\n",
        "if m==\"2\" and experiment in [\"3\", \"4\"]:\n",
        "  raise ValueError(f\"No experiment {experiment} for m=2\")\n",
        "if m==\"3\" and experiment in [\"P1\", \"P2\", \"P3\", \"P4\"]:\n",
        "  raise ValueError(f\"No experiment {experiment} for m=2\")\n",
        "\n",
        "if experiment in [\"1\", \"2\", \"3\", \"4\"]:\n",
        "  exp_name = f\"exp{experiment}\"\n",
        "else:\n",
        "  exp_name = f\"ortega_{experiment}\"\n",
        "\n",
        "if method == \"Value iteration\":\n",
        "  os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "  !python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m{m}/{exp_name} vi_runner.checkpoint_frequency={checkpoint_frequency}\n",
        "elif method == \"Simulation optimization\":\n",
        "  os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "  !python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m{m}/{exp_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MTrli3yEJgpd"
      },
      "outputs": [],
      "source": [
        "#@title Run an experiment for Scenario C\n",
        "m = \"3\" #@param [\"3\", \"5\", \"8\"]\n",
        "experiment = \"1\" #@param [\"1\", \"2\"]\n",
        "method = \"Value iteration\" #@param [\"Value iteration\", \"Simulation optimization\"]\n",
        "\n",
        "if method == \"Value iteration\":\n",
        "  if m == \"8\":\n",
        "    raise ValueError(\"Value iteration not feasible when m=8\")\n",
        "  os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "  !python run_value_iteration.py +experiment=mirjalili_perishable_platelet/m{m}/exp{experiment}\n",
        "elif method == \"Simulation optimization\":\n",
        "  os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "  !python run_optuna_simopt.py +experiment=mirjalili_perishable_platelet/m{m}/exp{experiment}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbo3JWiLq0fI"
      },
      "source": [
        "# Advanced"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tzlzAjSUq8UG"
      },
      "source": [
        "## Resuming value iteration from a checkpoint\n",
        "\n",
        "At the time of writing (February 2023), the Colab [FAQ](https://research.google.com/colaboratory/faq.html) states that the free tier of Google Colab has a maximum time limit of 12 hours but a session may also time out if left idle. The time limit can be extended using Colab Pro. \n",
        "\n",
        "The 12 hour time limit of the free tier is long enough to run all of the experiments except value iteration for Scenario C when $m=5$. In practice, we have found that our notebooks time out due to inactivity when running some of the shorter experiments. \n",
        "\n",
        "One possible solution to this is to resume value iteration from a checkpoint file. If you wish to do this, we recommend that you mount your Google Drive using the process described above. \n",
        "\n",
        "In the example below, there is no interruption. For illustrative purposes, we load a checkpoint from the temporary working directory, but in the event of a time-out there is no guarantee that it will still be available when restarting the runtime.\n",
        "\n",
        "By default, value iteration outputs are saved in an outputs directory in the value_iteration directory, with a path specifying the scenario, value of $m$, experiment ID, date and time, for example:\n",
        "`value_iteration/outputs/hendrix_perishable_substitution_two_product/m2/exp1/2023-02-07/12-53-07`. The checkpoints are saved in a subdirectory, called `checkpoints`. \n",
        "\n",
        "In this example, to ensure that the cells below run without needing to specify a date and time, we set a custom output directory using the command line argument `hydra.run.dir`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsIxK_eS6gDO"
      },
      "outputs": [],
      "source": [
        "# Run a complete experiment\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 hydra.run.dir='restore_cp_demo'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "me5ulOPk85AE"
      },
      "source": [
        "The experiment saves checkpoints and, by default, a log file (`run_value_iteration.log`), the policy (`policy.csv`), the final values (`V.csv`), and an output file that we use to record information for inclusion in results tables (`output_info.yaml`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58kpmAor6gBF"
      },
      "outputs": [],
      "source": [
        "!ls restore_cp_demo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuqnTH0q9K4u"
      },
      "source": [
        "Within the `checkpoints` subdirectory of the output, there is a checkpoint from the end of each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNv23q36f6C"
      },
      "outputs": [],
      "source": [
        "!ls restore_cp_demo/checkpoints"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp1xYRdS9SIG"
      },
      "source": [
        "We resume from a checkpoint by using the command line argument `vi_runner.resume_from_checkpoint` and providing the path to the checkpoint we want to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_phmKQO97P8w"
      },
      "outputs": [],
      "source": [
        "# Repeat the experiment, starting with a checkpoint for iteration 8\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "checkpoint_path = viso_jax_dir / \"viso_jax/value_iteration/restore_cp_demo/checkpoints/values_8.csv\"\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 vi_runner.resume_from_checkpoint={checkpoint_path} hydra.run.dir='restored_from_cp_demo'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6kWhwA387-8u"
      },
      "source": [
        "We can see that the outputs for value iteration from iteration 9 to 11 are the same as in the original run above, and the the metrics reported on the simulated rollouts are the same."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S5HINVU6q8O4"
      },
      "source": [
        "## Reducing the GPU memory demand"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VCqLZUmS-NQF"
      },
      "source": [
        "The default parallelism in the code has been set to run on the Nvidia GeForce RTX 3060, with 12GB of VRAM, on our development machine. \n",
        "\n",
        "In our recent experience of the free tier of Google Colab, we have been allocated an Nividia Tesla T4 with 15GB of VRAM and therefore this has not been a problem. However, the GPU allocated by Colab is not guaranteed and you may wish to run this notebook, or other code from the repository, on a GPU with less VRAM.\n",
        "\n",
        "If you encounted a GPU out-of-memory error, you can try to avoid it by reducing the amount of work performed in parallel as set out below."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "czAdAnKPrIgp"
      },
      "source": [
        "### Value iteration"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r7hWbtEt-6Md"
      },
      "source": [
        "For value iteration, the key setting is the maximum batch size: the number of states being simultaneously updated. This can be adjusted using the command line argument `vi_runner.max_batch_size`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWkcoPo1_Hjy"
      },
      "outputs": [],
      "source": [
        "# Run an experiment with a large max batch size\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 vi_runner.max_batch_size=5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eys0PkGk_SDN"
      },
      "outputs": [],
      "source": [
        "# Run an experiment with a small max batch size\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 vi_runner.max_batch_size=50"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gSnJAHTlrIbE"
      },
      "source": [
        "### Simulation optimization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9FABU1NLHLmG"
      },
      "source": [
        "For simulation optimization the key settings are `param_search.max_parallel_trials` (the number of different combinations of parameters for the heuristic policy to run in one iteration) and `param_search.num_rollouts` (the number of rollouts to run for each set of parameters for the heuristic policy). By default these are set at 50 and 4,000 respectively. For experiments that use Optuna NSGAII sampler we also use the comment line argument `param_search.sampler.population_size` to match `param_search.num_rollouts` so that the size of each generation of the genetic algorithm is the same as the number of trials being run in one iteration. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igse7KhMqoQt"
      },
      "outputs": [],
      "source": [
        "# Run a simulation optimization experiment with the default settings\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KINyatU_TLaz"
      },
      "outputs": [],
      "source": [
        "# Run an experiment that evaluates fewer combinations of parameters in parallel\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 param_search.max_parallel_trials=10 param_search.sampler.population_size=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noKIXiHGHLK4"
      },
      "outputs": [],
      "source": [
        "# Run an experiment with fewer rollouts per set of parameters\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 param_search.num_rollouts=1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "souzuEL7rX3H"
      },
      "outputs": [],
      "source": [
        "# Run an experiment that evaluates fewer combinations of parameters in parallel and runs fewer rollouts per set of parameters\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 param_search.max_parallel_trials=10 param_search.sampler.population_size=10  param_search.num_rollouts=1000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "awSd6GZ0JMqg"
      },
      "source": [
        "### Evaluation rollouts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6cqXfbGgJSVf"
      },
      "source": [
        "For both value iteration and simulation optimization we run 10,000 rollouts with the best identified policy by default. This number can be reduced using the command line argument `evaluation.num_rollouts`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy0aLGfzJMKi"
      },
      "outputs": [],
      "source": [
        "# Run a value iteration experiment with a fewer evaluation rollouts\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 evaluation.num_rollouts=5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU2OoHMUJsNw"
      },
      "outputs": [],
      "source": [
        "# Run a simulation optimization experiment with fewer evaluation rollouts\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 evaluation.num_rollouts=5000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4qMEDt5Q8s8N"
      },
      "source": [
        "## Running value iteration at single-precision"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb00Y30D8xCm"
      },
      "source": [
        "We explain in the paper that we have used double-precision numbers for our value iteration experiments, due to the instability in convergence we observed for some problems when using the default single-precision while conducting preliminary experiments.\n",
        "\n",
        "We provide the ability to switch between these options using the command line, as demonstrated below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrVEgptH9Q5H"
      },
      "outputs": [],
      "source": [
        "# Run value iteration at double-precision, the default in our configs (but not for JAX)\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/ortega_P4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXPXfycN9Q2g"
      },
      "outputs": [],
      "source": [
        "# Run value iteration at single-precision, the default for JAX\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/ortega_P4 vi_runner.checkpoint_frequency=0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9inWWDLTgFya"
      },
      "source": [
        "## Running experiments with different random seeds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9OS39hv_pLjr"
      },
      "source": [
        "Our experiments use seeds to ensure reproducibility. These seeds can be changed using command line arguments.\n",
        "\n",
        "JAX handles random number generation and seeding differently to other libraries like NumPy - we recommend reading this [tutorial](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#rngs-and-state). \n",
        "\n",
        "The seeds we set in the configuration files, and override below using the command line, are used to initialize an initial JAX PRNGKey. This key is then split to be passed to each call of a function that generates a random output."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "of1lqfJLgQBf"
      },
      "source": [
        "### Value iteration"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "__VJG8yup6Lv"
      },
      "source": [
        "A seed is only used at the evaluation stage of value iteration. It is used to make the stochastic elements of the transitions in the environment reproducible. \n",
        "\n",
        "We use the same seed for the evaluation stages of value iteration and simulation optimization so that, for a given experiment, it would be possible to perform pairwise comparisons to test how each policy performs when faced with the same pattern of demand (and any other stochastic elements in the transition). \n",
        "\n",
        "The command line argument for the seed is `evaluation.seed`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sADqEqgdp56H"
      },
      "outputs": [],
      "source": [
        "# Run value iteration and evaluate on scenarios generated using the default seed from the config file\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQxjII5YvltY"
      },
      "outputs": [],
      "source": [
        "# Run value iteration and evaluate on scenarios generated using a seed specified at the command line\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 evaluation.seed=999"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sMP4oHA_y54c"
      },
      "source": [
        "We can see from the results above that the evaluation results are similar, but different because they are based on two different sets of 10,000 rollouts."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PLETyqbsgSdv"
      },
      "source": [
        "### Simulation optimization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AUsRG0WFv4Hp"
      },
      "source": [
        "For simulation optimization we supply two different seeds using the configuration file. \n",
        "\n",
        "One, `evaluation.seed` is the same as for the value iteration experiments, and is used at the evaluation stage after the best parameters for the heuristic policy have been identified. \n",
        "\n",
        "The second, `param_search.seed` fulfills the the same function for the rollouts performed during the simulation optimization process.\n",
        "\n",
        "`param_search.seed` is also separately passed into our Optuna sampler to make the heuristic search of the policy parameter space deterministic. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYW1aqZXv3Uf"
      },
      "outputs": [],
      "source": [
        "# Run simulation optimization and evaluate on scenarios generated using the default seeds from the config file\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3IVK3k7gFSS"
      },
      "outputs": [],
      "source": [
        "# Run simulation optimization using a seed specified at the command line and evaluate on scenarios generated using the default param_seach.seed from the config file\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 param_search.seed=999"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYvAowXVyNGE"
      },
      "outputs": [],
      "source": [
        "# Run simulation optimization using the default evaluation.seed from the config file and evaluate on scenarios generated using the a seed specified at the command line\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=hendrix_perishable_substitution_two_product/m2/exp1 evaluation.seed=999"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9_AneCvq0X4S"
      },
      "source": [
        "We can see that the search process is different in the first and second cases, but both identified the same combination of parameters as the best. The evaluation outputs for the first and second case are the same - they use the same evaluation seed and therefore the policies are being evaluated on the same set of 10,000 rollouts.\n",
        "\n",
        "The third case follows the same search process as the first, but the evaluation outputs are different becauase they are calculated based on a different set of 10,000 rollouts."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "922SIS9Oq8KQ"
      },
      "source": [
        "## Changing a scenario setting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nZHToWThBfEK"
      },
      "source": [
        "Scenario settings are settings that relate to the problem description, for example the parameters of the demand distribution, the maximum useful life or the variable order cost. \n",
        "\n",
        "We use [hydra](https://hydra.cc/) for configuration, which supports composable configuration files. The final configuration for an experiment is therefore drawn from multiple yaml files.\n",
        "\n",
        "If you wish to change scenario settings, you should update the entry in the scenario settings config. The change will then be propogated to any other configs that require the same information. For example, when running value iteration, the scenario settings config feeds through both to the config that parameterises the class that performs value iteration (a value iteration runner) and the config that parameterises the class that manages the simulation rollouts of the final policy (a rollout wrapper).\n",
        "\n",
        "In the examples below, we run an experiment with the default settings followed by a modified version, changing one or more scenario settings at the command line."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7SkFAhek6uhV"
      },
      "source": [
        "### Value iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87UMHzcI2DlK"
      },
      "outputs": [],
      "source": [
        "# Run a value iteration experiment\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=de_moor_perishable/m2/exp1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xP7hVGJBazP"
      },
      "outputs": [],
      "source": [
        "# Run a value iteration experiment with a higher shortage cost\n",
        "os.chdir(viso_jax_dir / \"viso_jax/value_iteration\")\n",
        "!python run_value_iteration.py +experiment=de_moor_perishable/m2/exp1 scenario_settings.shortage_cost=10"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AtyQOaYX6xea"
      },
      "source": [
        "### Simulation optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa9cxSuxGvdu"
      },
      "outputs": [],
      "source": [
        "# Run a simulation optimization experiment\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=de_moor_perishable/m2/exp1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MvtN5h2EwqP"
      },
      "outputs": [],
      "source": [
        "#Run a simulation optimization experiment with a higher mean demand and higher max order quantity\n",
        "os.chdir(viso_jax_dir / \"viso_jax/simopt\")\n",
        "!python run_optuna_simopt.py +experiment=de_moor_perishable/m2/exp1 scenario_settings.demand_gamma_mean=8 scenario_settings.max_order_quantity=20"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TA3oa-zG2dhA"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
